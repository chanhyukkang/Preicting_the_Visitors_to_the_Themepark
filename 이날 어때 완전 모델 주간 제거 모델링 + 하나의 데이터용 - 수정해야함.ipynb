{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlgus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\dlgus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\dlgus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\dlgus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "일별test개수:  721\n",
      "최소 [  0.  -14.4 -18.  -10.7   0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0. ]\n",
      "최대 [1.000e+00 3.180e+01 2.870e+01 3.670e+01 2.400e+01 3.015e+02 1.224e+03\n",
      " 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00\n",
      " 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00\n",
      " 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00]\n",
      "최소입장객수 [2.]\n",
      "최대입장객수 [115002.]\n",
      "Train on 3609 samples, validate on 903 samples\n",
      "Epoch 1/10\n",
      "3609/3609 [==============================] - 16s 4ms/step - loss: 0.0058 - val_loss: 0.0026\n",
      "Epoch 2/10\n",
      "1550/3609 [===========>..................] - ETA: 9s - loss: 0.0044"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2dcde52cc900>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[0mearly_stop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m \u001b[0mmodel4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_train_tLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_sc_dropped\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_trainLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;31m#모델 세이브\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2977\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2979\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2980\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2937\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2938\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers, models\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import LSTM, Dense, concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#***************************파일을 읽고, 날짜 column생성*********************************\n",
    "df = pd.read_csv('SeoulGrandPark.csv', engine = 'python')    \n",
    "df[\"날짜\"] = df[\"년도\"].map(str) + '-' +df[\"월\"].map(str) + '-' + df[\"일\"].map(str)\n",
    "df = df.set_index('날짜')\n",
    "#**************************train set과 test set분할**************************************\n",
    "split_date_last = '2016-12-17'\n",
    "split_date_start = '2017-3-30'\n",
    "#*****************위는 DNN용 특성 데이터셋, 아래는 LSTM용 시계열 데이터(앞으로도 계속)***\n",
    "train = df.loc[:split_date_last]\n",
    "test = df.loc[split_date_start:]\n",
    "\n",
    "trainLSTM = df.loc[:split_date_last, ['일계']]\n",
    "testLSTM = df.loc[split_date_start:, ['일계']]\n",
    "#**************************데이터를 사용가능하도록 변환**********************************\n",
    "train['일계'] = train['일계'].str.replace(',', '')\n",
    "test['일계'] = test['일계'].str.replace(',', '')\n",
    "\n",
    "train['일계'] = train['일계'].astype('float')\n",
    "test['일계'] = test['일계'].astype('float')\n",
    "\n",
    "trainLSTM['일계'] = trainLSTM['일계'].str.replace(',', '')\n",
    "testLSTM['일계'] = testLSTM['일계'].str.replace(',', '')\n",
    "\n",
    "trainLSTM['일계'] = trainLSTM['일계'].astype('float')\n",
    "testLSTM['일계'] = testLSTM['일계'].astype('float')\n",
    "#***************************이어서 시계열 데이터만 처리********************************************\n",
    "#*******************************이제는 일단위 시계열 데이터 처리 (반복)***************************\n",
    "dayfrom = 14\n",
    "dayto = 42\n",
    "day = dayto - dayfrom\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "\n",
    "train_scLSTM = sc.fit_transform(trainLSTM)\n",
    "test_scLSTM = sc.transform(testLSTM)\n",
    "\n",
    "train_sc_dfLSTM = pd.DataFrame(train_scLSTM, columns=['Scaled'], index=trainLSTM.index)\n",
    "test_sc_dfLSTM = pd.DataFrame(test_scLSTM, columns=['Scaled'], index=testLSTM.index)\n",
    "\n",
    "for s in range(dayfrom, dayto):\n",
    "    train_sc_dfLSTM['shift_{}'.format(s)] = train_sc_dfLSTM['Scaled'].shift(s)\n",
    "    test_sc_dfLSTM['shift_{}'.format(s)] = test_sc_dfLSTM['Scaled'].shift(s)\n",
    "    \n",
    "X_trainLSTM = train_sc_dfLSTM.dropna().drop('Scaled', axis=1)\n",
    "y_trainLSTM = train_sc_dfLSTM.dropna()[['Scaled']]\n",
    "\n",
    "X_testLSTM = test_sc_dfLSTM.dropna().drop('Scaled', axis=1)\n",
    "y_testLSTM = test_sc_dfLSTM.dropna()[['Scaled']]\n",
    "#*****************************일단위 시계열 데이터를 model에 들어갈 수 있게 reshape*****************\n",
    "X_trainLSTM = X_trainLSTM.values\n",
    "X_testLSTM = X_testLSTM.values\n",
    "\n",
    "y_trainLSTM = y_trainLSTM.values\n",
    "y_testLSTM = y_testLSTM.values\n",
    "\n",
    "X_train_tLSTM = X_trainLSTM.reshape(X_trainLSTM.shape[0], day, 1)\n",
    "X_test_tLSTM = X_testLSTM.reshape(X_testLSTM.shape[0], day, 1)\n",
    "\n",
    "print('일별test개수: ', len(y_testLSTM))\n",
    "#******************************일단위 LSTM모델링***************************************************\n",
    "model = Sequential()\n",
    "model.add(LSTM(56, input_shape=(day, 1), return_sequences = True))\n",
    "model.add(LSTM(56))\n",
    "model.add(Dense(10))\n",
    "#*********이어서 DNN용 특성위주 데이터 정리 및 모델에 맞게 변환***********************************\n",
    "train_df = pd.DataFrame(train)\n",
    "test_df = pd.DataFrame(test)\n",
    "    \n",
    "X_train = train_df.drop(['일계', '년도', '일'], axis=1)\n",
    "y_train = train_df[['일계']]\n",
    "X_test = test_df.drop(['일계', '년도', '일'], axis=1)\n",
    "y_test = test_df[['일계']]\n",
    "    \n",
    "X_train = pd.get_dummies(X_train, columns=['요일', '월'])\n",
    "X_test = pd.get_dummies(X_test, columns=['요일', '월'])\n",
    "\n",
    "sc2 = MinMaxScaler()\n",
    "\n",
    "X_train_sc = sc2.fit_transform(X_train)\n",
    "X_test_sc = sc2.transform(X_test)\n",
    "\n",
    "y_train_sc = sc2.fit_transform(y_train)\n",
    "y_test_sc = sc2.transform(y_test)\n",
    "\n",
    "#*****************************************DNN 모델링*************************************************\n",
    "class DNN(models.Sequential):\n",
    "    def __init__(self, Nin):\n",
    "        super().__init__()\n",
    " \n",
    "        # 첫 번째 은닉층\n",
    "        self.add(layers.Dense(500, activation='relu',input_shape=(Nin,), name='Hidden-1'))\n",
    "        self.add(layers.Dense(500, activation='relu', name='Hidden-2'))\n",
    "        self.add(layers.Dense(10))\n",
    "        \n",
    "model3 = DNN(X_train_sc.shape[1])\n",
    "#***************************일단위 LSTM모델과 DNN모델을 concatenate 및 모델 생성**********************\n",
    "combinedInput = concatenate([model.output, model3.output])\n",
    "\n",
    "x = Dense(100)(combinedInput)\n",
    "x = Dense(100)(x)\n",
    "x = Dense(1)(x)\n",
    "\n",
    "model4 = Model(inputs=[model.input, model3.input], outputs=x)\n",
    "\n",
    "opt = Adam(lr=0.001)\n",
    "model4.compile(loss=\"mean_squared_error\", optimizer=opt)\n",
    "#************************************모델 학습************************************************************\n",
    "X_train_sc_dropped = X_train_sc[dayto-1:]#시계열데이터에 맞게 변환\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "model4.fit([X_train_tLSTM, X_train_sc_dropped], y_trainLSTM, validation_split = 0.2, epochs=10, batch_size=10, callbacks=[early_stop])\n",
    "\n",
    "#모델 세이브\n",
    "from keras.models import save_model\n",
    "model4.save('thisday2.h5')\n",
    "\n",
    "X_test_sc_dropped = X_test_sc[dayto-1:]#시계열데이터에 맞게 변환\n",
    "#**********************************plot을 이용한 그래프 그리기******************************************\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.rcParams['lines.linewidth'] = 0.5\n",
    "plt.title('Visitors Result')\n",
    "plt.xlabel('2017.3.30~2019.4.30')#수정해야 함\n",
    "plt.ylabel('visitors')\n",
    "ynewtest = sc.inverse_transform(y_testLSTM)\n",
    "plt.plot(ynewtest, label='actual')\n",
    "Y_pred = model4.predict([X_test_tLSTM, X_test_sc_dropped])\n",
    "ynew = sc.inverse_transform(Y_pred)\n",
    "plt.plot(ynew, label='predicted')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
